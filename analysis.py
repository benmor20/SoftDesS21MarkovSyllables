"""Contains code to split strings into words with syllables and perform
markov-chain word generation from those syllables, and analyze those words."""

#Some of this code will be redundant with code found in testing.py
from urllib import request
import markov_with_syllables as markov
import syllablizer
from collections import Counter
from nltk.corpus import words as english_words

def analyze_markov_syllables(analyze_text, verbose=False, max_words=10000, min_syllables=1):
    """
    Gather details about the analysis of the markov-generator words derived from
    the syllables of a given text.

    Args:
        analyze_text: A string of text to split into syllables, generate words from
            the syllables, and return analysis for. Alternatively, a list of
            strings to perform analysis on each
        verbose: A boolean that enables/disables printing stats for analyze_text.
            Default value is False.
        max_words: The number of words generated by the markov generator that will
            be used to analyze the text.Use "*" for the number of words in the
            original source, or a numerical value. Default value is 10000.
        min_syllables: The minimum number of 'syllables' a word must have to be
            included in the analysis. Syllable count is based on our syllable
            splitter, found in markov_with_syllables.py. Syllable counts are not
            always accurate, because the splitter works based on basic generalized
            rules like letter groupings and vowel-consonant sequences to identify
            syllables.
        
    Returns: A dictionary with the following items:
            unique_count, a count of words created by the markov generator from the
                corpus that didn't appear in the original corpus.
            regenerated_count, a count of words that the markov generator generated
                that also appear in the original corpus.
            most_common_syllables: A dictionary of the top 20 syllables in the corpus
                and the number of times they occur in the corpus.
            most_common_markov_words: A dictionary of the top 20 words from the markov
                generator's results for the corpus.
            average_word_length: The mean length of the words in the original corpus.
                average_unique_markov_word_length
        If analyze_text is a list of strings, returns a list of dicts, where
            each dict is as described above for each input text
    """
    print(type(analyze_text))
    texts = analyze_text
    is_list = type(analyze_text) is list
    if not is_list:
        texts = [analyze_text]
    
    text_info = []
    for index, text in enumerate(texts):
        if verbose:
            print(f"Text {index+1}: {#text name}]")
        print(type(text))

        sylls = markov.build_next_syllables(text)
        if verbose:
            print("Got syllables")
        all_words = set(markov.build_word_list(text))
        if verbose:
            print("Got word list")
        num_words = 0
        novel_words = set()
        words = set()
        novel_words_with_repeats = []
        if max_words == "*":
            max_words = len(all_words)
        while num_words < max_words:
            word = markov.generate_word(sylls)
            if len(syllablizer.syllablize(word)) >= min_syllables:
                words.add(word)
                if word not in all_words:
                    novel_words.add(word)
                    novel_words_with_repeats.append(word)
                num_words += 1
            if verbose and num_words % 1000 == 0:
                print(str(num_words))
        
        if verbose:
            for _ in range(10):
                print(novel_words.pop())
        
        #Calculate the number of markov-generated words not found in the original.
        unique_count=len(novel_words)
        #Calculate the number of words that the markov generator returned that also
        #appear in the original corpus
        regenerated_count = len(words)-len(novel_words)
        #Calculate the number of markov-generated words that are not English words
        
        if verbose:
            print(f"Unique: {unique_count} Regen: {regenerated_count}")

        all_english = english_words.words()
        actual_words = [word for word in words if word in all_english]
        english_count = len(actual_words)
        if verbose:
            print(f"English count: {english_count}. Sample:")
            for i in range(10):
                print(actual_words[i])

        #Calculate most common syllables in the original corpus.
        syll_list = markov.build_syllable_list(text)
        syll_list = [syll for word in syll_list for syll in word]
        most_common_syllables = Counter(syll_list).most_common(20)
        #Calculate most common markov-generated words from the corpus.
        most_common_novel_markov_words = Counter(novel_words_with_repeats).most_common(20)
        #Calculate the mean length of all words from the original corpus
        temp = [len(word) for word in all_words]
        average_word_length = float(sum(temp)/len(temp))
        #Calculate the mean length of the words that don't appear in the corpus
        #but are markov-generated based on the corpus.
        temp = [len(word) for word in novel_words]
        average_unique_markov_word_length = float(sum(temp)/len(temp))

        if verbose==True:
            print(f"Generated {num_words} words, {len(words)} of which were not repeats.")
            print(f"Of the unique words, {unique_count} are new and {regenerated_count} are from the text")
            print(f"Of the new words, {english_count} are actual words")

        text_info.append({
            "unique_count":unique_count,
            "regenerated_count":regenerated_count,
            "english_count":english_count,
            "most_common_syllables":most_common_syllables,
            "most_common_novel_markov_words": most_common_novel_markov_words,
            "average_word_length": average_word_length,
            "average_unique_markov_word_length": average_unique_markov_word_length
        })

    if is_list:
        return text_info
    return text_info[0]
